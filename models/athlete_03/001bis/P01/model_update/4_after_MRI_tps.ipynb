{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import opensim as osim\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping pandas from truncating long strings\n",
    "pd.set_option('display.max_colwidth', 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: e:\\DataFolder\\AlexP\\models\\athlete_03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'P01bis'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure correct individual name\n",
    "cwd = os.getcwd()\n",
    "root = os.path.dirname(os.path.dirname(os.path.dirname(cwd)))\n",
    "print(f\"Root directory: {root}\")\n",
    "tmp = cwd.split('\\\\')[len(root.split('\\\\')):]\n",
    "ind = 'P' + tmp[0][1:]\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Scaled Model with TPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_model = f\"3a_osim_markers/scaled_model_{ind}_joints.osim\"\n",
    "new_model_name = os.path.join(cwd, f'4_tps-bones-muscles-updated/{ind}_tps_transformed.osim')\n",
    "\n",
    "experimental_markers = r\"E:\\DataFolder\\AlexP\\simulations\\22_07_06\\static_01\\marker_experimental.trc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT : THESE SHOULD BE PERSON-SPECIFIC\n",
    "mass_text = '100'\n",
    "\n",
    "height_text = '1.83'\n",
    "\n",
    "age_text = '30'\n",
    "\n",
    "# path to experimental .trc file : <marker_file>\n",
    "static_df = pd.read_csv(experimental_markers, delimiter='\\t', skiprows=3, header=[0,1], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transformed Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_df = pd.concat([pd.read_csv('tps_warping_results/after_MRI/pelvis_bone_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_l_bone_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_r_bone_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/patella_l_bone_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/patella_r_bone_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_l_bone_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_r_bone_markers.csv', index_col=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data save to e:\\DataFolder\\AlexP\\models\\athlete_03\\001bis\\P01\\model_update\\tps_warping_results/after_MRI/markers_transformed.csv\n"
     ]
    }
   ],
   "source": [
    "markers_df = markers_df.set_index('name')\n",
    "markers_df.to_csv('tps_warping_results/after_MRI/markers_transformed.csv')\n",
    "print(f'data save to {os.path.join(cwd, \"tps_warping_results/after_MRI/markers_transformed.csv\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patella_l_in_femur = markers_df.loc['patella_l_in_femur_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patella_r_in_femur = markers_df.loc['patella_r_in_femur_r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transformed Muscle Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mscles_df = pd.concat([pd.read_csv('tps_warping_results/after_MRI/pelvis_muscle_paths.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_l_muscle_paths.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_r_muscle_paths.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/patella_l_muscle_paths.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/patella_r_muscle_paths.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_l_muscle_paths.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_r_muscle_paths.csv', index_col=0)])\n",
    "mscles_df = mscles_df.set_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transformed Wrapping Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrp_df  = pd.concat([pd.read_csv('tps_warping_results/after_MRI/pelvis_wrap_translations.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_l_wrap_translations.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_r_wrap_translations.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_l_wrap_translations.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_r_wrap_translations.csv', index_col=0)])\n",
    "wrp_df = wrp_df.set_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import transformed Skin Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df = pd.concat([pd.read_csv('tps_warping_results/after_MRI/pelvis_skin_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_l_skin_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/femur_r_skin_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_l_skin_markers.csv', index_col=0),\n",
    "            pd.read_csv('tps_warping_results/after_MRI/tibia_r_skin_markers.csv', index_col=0)])\n",
    "skin_df = skin_df.set_index('name')\n",
    "skin_df.to_csv('tps_warping_results/after_MRI/skin_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse current scaled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=ET.parse(scaled_model)\n",
    "root = tree.getroot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update reference geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_geom_dic = {'body': [], 'Mesh name' : [], 'Mesh file' : []}\n",
    "\n",
    "ref_geom_dic['body'].append(\"pelvis\"); ref_geom_dic['Mesh name'].append(\"pelvis_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\r_pelvis.stl'))\n",
    "ref_geom_dic['body'].append(\"pelvis\"); ref_geom_dic['Mesh name'].append(\"pelvis_geom_2\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\l_pelvis.stl'))\n",
    "ref_geom_dic['body'].append(\"pelvis\"); ref_geom_dic['Mesh name'].append(\"pelvis_geom_3\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\sacrum.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"femur_r\"); ref_geom_dic['Mesh name'].append(\"femur_r_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\femur_r.stl'))\n",
    "ref_geom_dic['body'].append(\"femur_l\"); ref_geom_dic['Mesh name'].append(\"femur_l_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\femur_l.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"tibia_r\"); ref_geom_dic['Mesh name'].append(\"tibia_r_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\tibia_r.stl'))\n",
    "ref_geom_dic['body'].append(\"tibia_r\"); ref_geom_dic['Mesh name'].append(\"tibia_r_geom_2\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\fibula_r.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"tibia_l\"); ref_geom_dic['Mesh name'].append(\"tibia_l_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\tibia_l.stl'))\n",
    "ref_geom_dic['body'].append(\"tibia_l\"); ref_geom_dic['Mesh name'].append(\"tibia_l_geom_2\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\fibula_l.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"patella_r\"); ref_geom_dic['Mesh name'].append(\"patella_r_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\patella_r.stl'))\n",
    "ref_geom_dic['body'].append(\"patella_l\"); ref_geom_dic['Mesh name'].append(\"patella_l_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\patella_l.stl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_geom_df = pd.DataFrame(ref_geom_dic).set_index('Mesh name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Mesh in root.iter('Mesh'):\n",
    "    point = Mesh.attrib['name']\n",
    "    if point in ref_geom_df.index:\n",
    "        new_text = ref_geom_df.loc[point, 'Mesh file']\n",
    "        # print(point, new_text)\n",
    "        Mesh.find('mesh_file').text = new_text\n",
    "        Mesh.find('scale_factors').text = '1 1 1'\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update muscle paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscle_path_names = []\n",
    "muscle_path_old = []\n",
    "muscle_path_new = []\n",
    "\n",
    "for PathPoint in root.iter('PathPoint'):\n",
    "    point = PathPoint.attrib['name']   \n",
    "    if point in mscles_df.index:      \n",
    "        \n",
    "        location = mscles_df.loc[point, 'location']\n",
    "        new_text = location[1:-1]\n",
    "        muscle_path_names.append(point)\n",
    "        muscle_path_new.append(new_text)\n",
    "        muscle_path_old.append(PathPoint.find('location').text)\n",
    "\n",
    "        PathPoint.find('location').text = new_text\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscle_path_new_df = pd.DataFrame([[float(i) for i in point.split()] for point in muscle_path_new], index=muscle_path_names, columns=['x','y','z'])\n",
    "muscle_path_old_df = pd.DataFrame([[float(i) for i in point.split()] for point in muscle_path_old], index=muscle_path_names, columns=['x','y','z'])\n",
    "\n",
    "muscle_path_diff_df = muscle_path_old_df - muscle_path_new_df\n",
    "muscle_path_diff_df['d'] = (muscle_path_diff_df['x']**2+muscle_path_diff_df['y']**2+muscle_path_diff_df['z']**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update muscle wrapping surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_cyl_name = []\n",
    "wrap_transl_old = []\n",
    "wrap_transl_new = []\n",
    "wrap_radius_old = []\n",
    "wrap_radius_new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Flex_at_femhead_r    [-0.00505375816651461  0.00081413088808978  0.00936748614800365]\n",
      "Flex_at_femhead_r    [-0.00265201563865854 -0.00068066765426039  0.01179596002901365]\n",
      "Name: location, dtype: object is a pandas Series, selecting the first row\n",
      "name\n",
      "Flex_at_femhead_r    [-0.00505375816651461  0.00081413088808978  0.00936748614800365]\n",
      "Flex_at_femhead_r    [-0.00265201563865854 -0.00068066765426039  0.01179596002901365]\n",
      "Name: location, dtype: object is a pandas Series, selecting the first row\n"
     ]
    }
   ],
   "source": [
    "for WrapCylinder in root.iter('WrapCylinder'):\n",
    "    point = WrapCylinder.attrib['name']\n",
    "    wrap_cyl_name.append(point)\n",
    "\n",
    "    if point in wrp_df.index:\n",
    "        translation = wrp_df.loc[point, 'location']\n",
    "        wrap_transl_new.append(translation)\n",
    "        wrap_transl_old.append(WrapCylinder.find('translation').text)\n",
    "        # Defensive: check if translation is a pandas Series (should not be, but just in case)\n",
    "        if isinstance(translation, pd.Series):\n",
    "            print(f'{translation} is a pandas Series, selecting the first row')\n",
    "            translation = translation.iloc[0]\n",
    "            \n",
    "        WrapCylinder.find('translation').text = translation[1:-1]\n",
    "        \n",
    "        \n",
    "\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Translation of joint centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torso_origin_in_pelvis = markers_df.loc['torso_origin_in_pelvis', 'location']\n",
    "\n",
    "femur_r_center_in_pelvis = markers_df.loc['femur_r_center_in_pelvis', 'location']\n",
    "femur_l_center_in_pelvis = markers_df.loc['femur_l_center_in_pelvis', 'location']\n",
    "knee_l_center_in_femur = markers_df.loc['knee_l_center_in_femur_l', 'location']\n",
    "knee_r_center_in_femur = markers_df.loc['knee_r_center_in_femur_r', 'location']\n",
    "patella_l_center_in_femur = markers_df.loc['patella_l_in_femur_l', 'location']\n",
    "patella_r_center_in_femur = markers_df.loc['patella_r_in_femur_r', 'location']\n",
    "\n",
    "talus_l_center_in_tibia = markers_df.loc['talus_l_center_in_tibia', 'location']\n",
    "talus_r_center_in_tibia = markers_df.loc['talus_r_center_in_tibia', 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_centers_names = []\n",
    "joint_centers_new = []\n",
    "joint_centers_old = []\n",
    "\n",
    "for joint in root.iter('CustomJoint'):\n",
    "    \n",
    "    name = joint.attrib['name']\n",
    "    if joint.attrib['name'] ==  \"back\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"pelvis_offset\":\n",
    "                new_text = torso_origin_in_pelvis[1:-1]\n",
    "                joint_centers_names.append(\"back\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "            else: pass\n",
    "\n",
    "    if joint.attrib['name'] ==  \"hip_r\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"pelvis_offset\":                \n",
    "                new_text = femur_r_center_in_pelvis[1:-1]\n",
    "                joint_centers_names.append(\"hip_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)           \n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "            else: pass\n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"hip_l\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"pelvis_offset\":\n",
    "                new_text = femur_l_center_in_pelvis[1:-1]\n",
    "                joint_centers_names.append(\"hip_l\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "            else: pass\n",
    "            \n",
    "    elif joint.attrib['name'] ==  \"walker_knee_r\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"femur_r_offset\":\n",
    "                new_text = knee_r_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"walker_knee_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "            #if frame.attrib['name'] == \"tibia_r_offset\":\n",
    "            #    new_text = f\"{walker_knee_r_tibia_r_offset[0]}, {walker_knee_r_tibia_r_offset[1]}, {walker_knee_r_tibia_r_offset[2]}\"\n",
    "            #    frame.find('translation').text = new_text\n",
    "            else: pass    \n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"walker_knee_l\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"femur_l_offset\":\n",
    "                new_text = knee_l_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"walker_knee_l\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "    #        if frame.attrib['name'] == \"tibia_l_offset\":\n",
    "    #            new_text = f\"{walker_knee_l_tibia_l_offset[0]}, {walker_knee_l_tibia_l_offset[1]}, {walker_knee_l_tibia_l_offset[2]}\"\n",
    "    #            frame.find('translation').text = new_text\n",
    "            else: pass\n",
    "\n",
    "    elif joint.attrib['name'] ==  \"patellofemoral_r\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"femur_r_offset\":               \n",
    "                new_text = knee_r_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"patellofemoral_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"patellofemoral_l\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"femur_l_offset\":              \n",
    "                new_text = knee_l_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"patellofemoral_l\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "\n",
    "for joint in root.iter('PinJoint'):   \n",
    "    name = joint.attrib['name']\n",
    "    if joint.attrib['name'] ==  \"ankle_r\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"tibia_r_offset\":              \n",
    "                new_text = talus_r_center_in_tibia [1:-1]\n",
    "                joint_centers_names.append(\"ankle_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"ankle_l\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"tibia_l_offset\":              \n",
    "                new_text = talus_l_center_in_tibia [1:-1]              \n",
    "                joint_centers_names.append(\"ankle_l\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)              \n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Markers for Joint Positions in Parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_names = ['torso_origin_in_pelvis','femur_l_center_in_pelvis', 'femur_r_center_in_pelvis',  'knee_l_center_in_femur_l', 'patella_l_in_femur_l', 'knee_r_center_in_femur_r', 'patella_r_in_femur_r']\n",
    "\n",
    "for marker in root.iter('Marker'):\n",
    "    name = marker.attrib['name']\n",
    "    if name == 'ankle_l_tibia_l_offset':\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = markers_df.loc['talus_l_center_in_tibia', 'location']\n",
    "        marker.find('location').text = new_text[1:-1]\n",
    "    elif name == 'ankle_r_tibia_r_offset':\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = markers_df.loc['talus_r_center_in_tibia', 'location']\n",
    "        marker.find('location').text = new_text[1:-1]\n",
    "    elif name in m_names:\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = markers_df.loc[name, 'location']\n",
    "        marker.find('location').text = new_text[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Skin Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker in root.iter('Marker'):\n",
    "    name = marker.attrib['name']\n",
    "    if name in list(skin_df.index):\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = skin_df.loc[name, 'location']\n",
    "        marker.find('location').text = new_text[1:-1]\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export transformed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xml.etree.ElementTree.ElementTree object at 0x000001CBFFC10850>\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of patella_l_in_femur: <class 'pandas.core.series.Series'>\n",
      "Value of patella_l_in_femur: body                                                                 femur_l\n",
      "location    [ 0.04363238677200714 -0.4128031117130943   0.00217404444689124]\n",
      "Name: patella_l_in_femur_l, dtype: object\n",
      "\n",
      "Type of patella_r_in_femur: <class 'pandas.core.series.Series'>\n",
      "Value of patella_r_in_femur: body                                                                 femur_r\n",
      "location    [ 0.04543757553456587 -0.41757370067727007 -0.002547464627669  ]\n",
      "Name: patella_r_in_femur_r, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the types and values of problematic variables\n",
    "print(\"Type of patella_l_in_femur:\", type(patella_l_in_femur))\n",
    "print(\"Value of patella_l_in_femur:\", patella_l_in_femur)\n",
    "print()\n",
    "print(\"Type of patella_r_in_femur:\", type(patella_r_in_femur))\n",
    "print(\"Value of patella_r_in_femur:\", patella_r_in_femur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕵️  Searching for pandas objects in the XML tree...\n",
      "🐛 PROBLEM FOUND in element: <translation>\n",
      "   - The .text content is a pandas object.\n",
      "   - Value: Series([], )\n",
      "🐛 PROBLEM FOUND in element: <translation>\n",
      "   - The .text content is a pandas object.\n",
      "   - Value: Series([], )\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def find_pandas_in_tree(root_element):\n",
    "    \"\"\"\n",
    "    Iterates through an ElementTree and finds elements where the .text\n",
    "    or an attribute value is a pandas Series or DataFrame.\n",
    "\n",
    "    Args:\n",
    "        root_element: The root element of the XML tree to search.\n",
    "    \"\"\"\n",
    "    print(\"🕵️  Searching for pandas objects in the XML tree...\")\n",
    "    found_issue = False\n",
    "    # root_element.iter() visits every element in the tree\n",
    "    for element in root_element.iter():\n",
    "        # 1. Check the element's text content\n",
    "        if isinstance(element.text, (pd.Series, pd.DataFrame)):\n",
    "            found_issue = True\n",
    "            print(f\"🐛 PROBLEM FOUND in element: <{element.tag}>\")\n",
    "            print(f\"   - The .text content is a pandas object.\")\n",
    "            print(f\"   - Value: {element.text.to_string()}\") # Use .to_string() for clean printing\n",
    "            \n",
    "            element.text = element.text.to_string()  # Convert to string for XML compatibility\n",
    "            \n",
    "        # 2. Check all of the element's attributes\n",
    "        for key, value in element.attrib.items():\n",
    "            if isinstance(value, (pd.Series, pd.DataFrame)):\n",
    "                found_issue = True\n",
    "                print(f\"🐛 PROBLEM FOUND in element: <{element.tag}>\")\n",
    "                print(f\"   - The attribute '{key}' is a pandas object.\")\n",
    "                print(f\"   - Value: {value.to_string()}\")\n",
    "                \n",
    "                # if found_issue make them a string\n",
    "                element.set(key, value.to_string())                \n",
    "    \n",
    "    if not found_issue:\n",
    "        print(\"✅ No pandas objects found. The tree looks clean!\")\n",
    "        \n",
    "    return root_element\n",
    "\n",
    "# --- HOW TO USE IT ---\n",
    "\n",
    "# Assume 'tree' is your ElementTree object from your code\n",
    "# For example: \n",
    "\n",
    "# Before you call tree.write(), run the diagnostic function:\n",
    "root = find_pandas_in_tree(root) \n",
    "\n",
    "# Your original failing line:\n",
    "# tree.write(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved in e:\\DataFolder\\AlexP\\models\\athlete_03\\001bis\\P01\\model_update\\4_tps-bones-muscles-updated/P01bis_tps_transformed.osim\n"
     ]
    }
   ],
   "source": [
    "tree.write(new_model_name)\n",
    "print(f'data saved in {new_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale muscle fibres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fibre_scale_script import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define models\n",
    "# generic_model = '../templates/RajagopalModified_generic_copy.osim'\n",
    "# model_to_update = f'4_tps-bones-muscles-updated/{ind}_tps_transformed.osim'\n",
    "# updated_model = f'4_tps-bones-muscles-updated/{ind}_tps_fibres_updated.osim'\n",
    "\n",
    "# # run scripts\n",
    "# osimModel_opt, SimInfo = optimMuscleParams(generic_model, model_to_update, 2, '7_tps-fibres-updated/logging')\n",
    "\n",
    "# # printing the optimized model\n",
    "# osimModel_opt.printToXML(updated_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit skin markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\DataFolder\\\\AlexP\\\\models\\\\athlete_03\\\\001bis\\\\P01\\\\model_update\\\\4_tps-bones-muscles-updated/P01bis_tps_transformed.osim'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit Skin Markers\n",
    "# <model_file>\n",
    "model = new_model_name # f'4_tps-bones-muscles-updated/{}_tps_fibres_updated.osim' #\n",
    "\n",
    "# <marker_set_file>\n",
    "path_to_generic_marker_set = '4_tps-bones-muscles-updated/markers.xml' #'unassigned' #'../templates/scaling_EXP_Markers_to_Scale_final_3.xml'\n",
    "\n",
    "# <time_range>'\n",
    "time_range = f' 0 {list(static_df.loc[static_df.shape[0], \"Time\"])[0] }'\n",
    "\n",
    "# <output_scale_file>\n",
    "path_to_model = '4_tps-bones-muscles-updated'\n",
    "output_scale_file = os.path.join(path_to_model, 'marker_placer.txt')\n",
    "output_scaling_settings = os.path.join(path_to_model, f'marker_placer_{ind}.xml')\n",
    "output_model_file = os.path.join(path_to_model, f'{ind}_tps_fibres_skin_updated.osim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4_tps-bones-muscles-updated\\\\marker_placer_P01bis.xml'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_scaling_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the .xml with markers in body frames\n",
    "scaling_tree=ET.parse(\"../templates/marker_placer.xml\")\n",
    "scaling_root = scaling_tree.getroot()\n",
    "\n",
    "for generic_model in scaling_root.iter('model_file'):\n",
    "    generic_model.text = model\n",
    "for generic_marker_set in scaling_root.iter('marker_set_file'):\n",
    "    generic_marker_set.text = path_to_generic_marker_set\n",
    "\n",
    "for exp_markers in scaling_root.iter('marker_file'):\n",
    "    exp_markers.text = experimental_markers\n",
    "\n",
    "for time in scaling_root.iter('time_range'):\n",
    "    time.text = time_range\n",
    "for output in scaling_root.iter('output_model_file'):\n",
    "    output.text = output_model_file\n",
    "for scale in scaling_root.iter('output_scale_file'):\n",
    "    scale.text = output_scale_file\n",
    "for generic_marker_set in scaling_root.iter('marker_set_file'):\n",
    "    generic_marker_set.text = path_to_generic_marker_set\n",
    "\n",
    "for time in scaling_root.iter('time_range'):\n",
    "    time.text = time_range\n",
    "for output in scaling_root.iter('output_model_file'):\n",
    "    output.text = output_model_file\n",
    "for scale in scaling_root.iter('output_scale_file'):\n",
    "    scale.text = output_scale_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling settings saved to 4_tps-bones-muscles-updated\\marker_placer_P01bis.xml\n"
     ]
    }
   ],
   "source": [
    "scaling_tree.write(output_scaling_settings)\n",
    "print(f'Scaling settings saved to {output_scaling_settings}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a ScaleTool object using the configuration file.\n",
    "# scale_tool = osim.ScaleTool(output_scaling_settings)\n",
    "\n",
    "# # Print some information of the config file to test everything is correct.\n",
    "# print(\"Name:\", scale_tool.getName())\n",
    "# print(\"Subject Mass:\", scale_tool.getSubjectMass())\n",
    "# print(\"Subject Height:\", scale_tool.getSubjectHeight())\n",
    "# print(\"Notes:\", scale_tool.getPropertyByName(\"notes\").toString())\n",
    "# print()\n",
    "# # Get model marker file name.\n",
    "# generic_model_maker = scale_tool.getGenericModelMaker()\n",
    "# print(\"Marker Set File Name:\", generic_model_maker.getMarkerSetFileName())\n",
    "# print(\"Model File Name:\", generic_model_maker.getModelFileName())\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_tool.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bas\\miniconda3\\envs\\py311\\Lib\\subprocess.py:1016: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Preparing to run ScaleTool.\n",
      "\n",
      "[info] Processing subject Rajagopal-generic-scaled-scaled...\n",
      "\n",
      "[info] Step 1: Loading generic model\n",
      "\n",
      "[info] Loaded model Rajagopal-generic-scaled from file e:\\DataFolder\\AlexP\\models\\athlete_03\\001bis\\P01\\model_update\\4_tps-bones-muscles-updated\\P01bis_tps_transformed.osim\n",
      "\n",
      "[warning] Couldn't find file 'bones\\r_pelvis.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\l_pelvis.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'sacrum.vtp'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\femur_r.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\tibia_r.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\fibula_r.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\patella_r.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'r_talus.vtp'.\n",
      "\n",
      "[warning] Couldn't find file 'r_foot.vtp'.\n",
      "\n",
      "[warning] Couldn't find file 'r_bofoot.vtp'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\femur_l.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\tibia_l.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\fibula_l.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'bones\\patella_l.stl'.\n",
      "\n",
      "[warning] Couldn't find file 'l_talus.vtp'.\n",
      "\n",
      "[warning] Couldn't find file 'l_foot.vtp'.\n",
      "\n",
      "[warning] Couldn't find file 'l_bofoot.vtp'.\n",
      "\n",
      "[info] Loading marker set from '4_tps-bones-muscles-updated/markers.xml'.\n",
      "\n",
      "[error] Object: Cannot open file e:\\DataFolder\\AlexP\\models\\athlete_03\\001bis\\P01\\model_update\\4_tps-bones-muscles-updated\\markers.xml. It may not exist or you do not have permission to read it.\n",
      "\n",
      "\tThrown at Object.cpp:106 in Object().\n",
      "\n",
      "[error] Unable to load the generic model or marker set file.\n",
      "\n",
      "[error] ScaleTool: No model specified.\n",
      "\n",
      "[error] ScaleTool: No model specified.\n",
      "\n",
      "\n",
      "Return code:  None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from simFunctions import runProgram\n",
    "\n",
    "cmdprog = 'opensim-cmd'\n",
    "cmdtool = 'run-tool'\n",
    "cmdfile = output_scaling_settings\n",
    "cmdfull = [cmdprog, cmdtool, cmdfile]\n",
    "rc = runProgram(cmdfull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Wrapping Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '4_tps-bones-muscles-updated/P01bis_tps_fibres_skin_updated.osim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m updated_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4_tps-bones-muscles-updated/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_tps_fibres_skin_wrp_updated.osim\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# function to extract muscle paths, wrapping surfaces info and joint info from an osim model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# returns three dataframes: muscles, surfaces and joints\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m fix_wraps \u001b[38;5;241m=\u001b[39m \u001b[43mFixWraps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_update\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\DataFolder\\AlexP\\models\\athlete_03\\001bis\\P01\\model_update\\wrap_scripts.py:16\u001b[0m, in \u001b[0;36mFixWraps.__init__\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model_path\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\DataFolder\\AlexP\\models\\athlete_03\\001bis\\P01\\model_update\\wrap_scripts.py:19\u001b[0m, in \u001b[0;36mFixWraps.get_model_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_info\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     tree_model \u001b[38;5;241m=\u001b[39m \u001b[43mET\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     root_model \u001b[38;5;241m=\u001b[39m tree_model\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Extract the muscle path points\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bas\\miniconda3\\envs\\py311\\Lib\\xml\\etree\\ElementTree.py:1219\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \n\u001b[0;32m   1217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m tree \u001b[38;5;241m=\u001b[39m ElementTree()\n\u001b[1;32m-> 1219\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32mc:\\Users\\Bas\\miniconda3\\envs\\py311\\Lib\\xml\\etree\\ElementTree.py:570\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    568\u001b[0m close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 570\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m     close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '4_tps-bones-muscles-updated/P01bis_tps_fibres_skin_updated.osim'"
     ]
    }
   ],
   "source": [
    "from wrap_scripts import *\n",
    "\n",
    "model_to_update = f'4_tps-bones-muscles-updated/{ind}_tps_fibres_skin_updated.osim'\n",
    "updated_model = f'4_tps-bones-muscles-updated/{ind}_tps_fibres_skin_wrp_updated.osim'\n",
    "# function to extract muscle paths, wrapping surfaces info and joint info from an osim model\n",
    "# returns three dataframes: muscles, surfaces and joints\n",
    "fix_wraps = FixWraps(model_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrp_adjust_dict = fix_wraps.collect_wrp_details()\n",
    "wrp_adjust_df = pd.DataFrame.from_dict(wrp_adjust_dict)\n",
    "wrp_adjust_df.set_index(pd.Index(['body', 'transl', 'rad', 'point_label', 'point', 'point_body', 'joint_location', 'joint_location+point', 'dist_to_transl',  'dist']), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrp_adjust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print points whose location is too far into radius for an automatic adjustment\n",
    "manual = []\n",
    "for col in wrp_adjust_df.columns:\n",
    "    if wrp_adjust_df.loc['dist', col] < wrp_adjust_df.loc['rad', col]-0.01:\n",
    "        print(col, ':', wrp_adjust_df.loc['point_label', col])\n",
    "        manual.append(col)\n",
    "\n",
    "# ignore patella points for now\n",
    "# adjust other points or wrapping surfaces manually for the input model and run the script again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update model\n",
    "tree_model = ET.parse(model_to_update)\n",
    "root = tree_model.getroot()\n",
    "\n",
    "wrp_to_change = [i for i in wrp_adjust_df.columns if i not in manual]\n",
    "\n",
    "for WrapCylinder in root.iter('WrapCylinder'):\n",
    "    name = WrapCylinder.attrib['name']\n",
    "    if name in wrp_to_change:\n",
    "        print(name)\n",
    "        radius = wrp_adjust_df.loc['rad', name]\n",
    "        print('old_radius', radius)\n",
    "        new_rad = wrp_adjust_df.loc['dist', name]\n",
    "        print('new_radius', new_rad)\n",
    "        radius_new_text = str(new_rad-0.01)\n",
    "        WrapCylinder.find('radius').text = radius_new_text\n",
    "\n",
    "tree_model.write(updated_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>IN OPENSIM GUI</b> \n",
    "Open the updated model. Activate wrapping surfaces in the list od surfaces whose adjustment is more than 0.02 above and related muscles. Make sure displayed surfaces do not overlap -- switch on one at a time. In the list of muscles, highlight and display the related muscle. In the properties window for that muscle, click on '...' for the muscle path, choose (by cklicking the left square) the listed via point. Interact with the 3D view to pull the via point just outside of the wrapping surface.\n",
    "\n",
    "Once finished with the list, <b> save the model </b>.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
